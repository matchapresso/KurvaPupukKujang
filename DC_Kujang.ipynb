{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "h4_OkUiJRxWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "roboflow_key = userdata.get('roboflow_key')"
      ],
      "metadata": {
        "id": "qlj4F12-4aOM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=roboflow_key)\n",
        "project = rf.workspace(\"smokefirev1\").project(\"firesmoke-uendo\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"folder\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHa-zaR8lLu1",
        "outputId": "7ac6cbc6-8603-4a89-89d3-8917207a7cee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.40-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.7.4)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.53.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Downloading roboflow-1.1.40-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, python-dotenv, requests-toolbelt, roboflow\n",
            "Successfully installed filetype-1.2.0 python-dotenv-1.0.1 requests-toolbelt-1.0.0 roboflow-1.1.40\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in firesmoke-2 to folder:: 100%|██████████| 424629/424629 [00:12<00:00, 33752.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to firesmoke-2 in folder:: 100%|██████████| 9910/9910 [00:02<00:00, 3999.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf /content/firesmoke-2/test/fire"
      ],
      "metadata": {
        "id": "FKv9BamXmtDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf /content/firesmoke-2/train/fire"
      ],
      "metadata": {
        "id": "8Jocl6ISnFwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.rmtree(\"/content/firesmoke-2/train/default fire smoke\")"
      ],
      "metadata": {
        "id": "6VexLDukngQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "root_dir = \"/content/firesmoke-2/train\"\n",
        "\n",
        "def delete_checkpoints(root_dir):\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "        if '.ipynb_checkpoints' in dirs:\n",
        "            dir_path = os.path.join(root, '.ipynb_checkpoints')\n",
        "            shutil.rmtree(dir_path)\n",
        "            print(f\"Deleted {dir_path}\")\n",
        "\n",
        "delete_checkpoints('.')\n"
      ],
      "metadata": {
        "id": "uqRsGKxhpqXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Path to your dataset folder\n",
        "train_path = '/content/firesmoke-2/train'\n",
        "test_path = \"/content/firesmoke-2/test\"\n",
        "\n",
        "# Load images and labels\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for label in os.listdir(folder):\n",
        "        label_path = os.path.join(folder, label)\n",
        "        if os.path.isdir(label_path):\n",
        "            for filename in os.listdir(label_path):\n",
        "                img_path = os.path.join(label_path, filename)\n",
        "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                if img is not None:\n",
        "                    img = cv2.resize(img, (64, 64))  # Resize image to fixed size\n",
        "                    images.append(img.flatten())  # Flatten the image\n",
        "                    labels.append(label)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load dataset\n",
        "X_train, y_train = load_images_from_folder(train_path)\n",
        "X_test, y_test = load_images_from_folder(test_path)\n",
        "\n",
        "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
        "X_test, y_test = shuffle(X_test, y_test, random_state=42)\n",
        "\n",
        "# Encode labels to integers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-guPfE__sfQ",
        "outputId": "0a820c28-1a31-4b56-da7b-02569769ac5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "accuracy = f1_score(y_test, y_pred)\n",
        "print(f'F1: {accuracy:.2f}')\n",
        "\n",
        "accuracy = precision_score(y_test, y_pred)\n",
        "print(f'Precision: {accuracy:.2f}')\n",
        "\n",
        "accuracy = recall_score(y_test, y_pred)\n",
        "print(f'Recall: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEFyGnCCBeO3",
        "outputId": "f18d7873-a2fe-459c-c811-c7839a49e7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.74\n",
            "F1: 0.78\n",
            "Precision: 0.79\n",
            "Recall: 0.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "from PIL import Image\n",
        "\n",
        "url = \"https://cdn.medcom.id/dynamic/content/2020/09/29/1193467/aUGWkuAJen.jpeg?w=1024\"\n",
        "urllib.request.urlretrieve(url, \"noasap1.png\")\n",
        "\n",
        "url = \"https://th.bing.com/th/id/OIP.qsYlpLu-jjaBS5FWT4Y-dQAAAA?rs=1&pid=ImgDetMain\"\n",
        "urllib.request.urlretrieve(url, \"asap1.png\")\n",
        "\n",
        "url = \"https://awsimages.detik.net.id/community/media/visual/2022/07/28/pkt-pastikan-kondisi-kondusif-pasca-pabrik-alami-over-firing-1_169.jpeg?w=650&q=80\"\n",
        "urllib.request.urlretrieve(url, \"noasap2.jpeg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N9Q-pCyB9em",
        "outputId": "66bc375c-4958-4839-9ab6-39472630cbe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('noasap2.jpeg', <http.client.HTTPMessage at 0x7e55c34098a0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images(img_path, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is not None:\n",
        "      img = cv2.resize(img, (64, 64))  # Resize image to fixed size\n",
        "      images.append(img.flatten())  # Flatten the image\n",
        "      labels.append(label)\n",
        "    return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "FZ_8p3mMCehK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = load_images(\"/content/asap1.png\", \"smoke\")\n",
        "label = label_encoder.transform(label)\n",
        "image = scaler.transform(image)\n",
        "pred = clf.predict(image)\n",
        "print(label_encoder.inverse_transform(pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoilPm7kC7Z6",
        "outputId": "67d5b728-dbf1-41aa-a2e9-ebf6a5e69643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['smoke']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = load_images(\"/content/noasap1.png\", \"default\")\n",
        "label = label_encoder.transform(label)\n",
        "image = scaler.transform(image)\n",
        "pred = clf.predict(image)\n",
        "print(label_encoder.inverse_transform(pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNayYXpFDItS",
        "outputId": "d67e9eec-a655-4e01-8033-69fc76f0e1ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['default']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = load_images(\"//content/noasap2.jpeg\", \"default\")\n",
        "label = label_encoder.transform(label)\n",
        "image = scaler.transform(image)\n",
        "pred = clf.predict(image)\n",
        "print(label_encoder.inverse_transform(pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEIpbG5ZDjBA",
        "outputId": "4880c7e2-9cdf-4dd9-c783-4601397a087f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['default']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# save\n",
        "with open('model.pkl','wb') as f:\n",
        "    pickle.dump(clf,f)"
      ],
      "metadata": {
        "id": "g-8iC5UZFg7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save\n",
        "with open('image_scaler.pkl','wb') as f:\n",
        "    pickle.dump(scaler,f)\n",
        "\n",
        "with open('label_encoder.pkl','wb') as f:\n",
        "    pickle.dump(label_encoder,f)"
      ],
      "metadata": {
        "id": "k4IToUOMFiES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a parameter grid\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 9],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Create a decision tree classifier\n",
        "clf_default = DecisionTreeClassifier()\n",
        "\n",
        "# Perform grid search\n",
        "grid_search = GridSearchCV(clf_default, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Print the best parameters\n",
        "print(grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQFU5CM0GEHF",
        "outputId": "6f87eb4d-8f75-4c21-bd58-4b98a197f469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the Decision Tree Classifier\n",
        "clf_tuning = DecisionTreeClassifier(max_depth= 5, min_samples_leaf=4, min_samples_split=10)\n",
        "clf_tuning.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf_tuning.predict(X_test)"
      ],
      "metadata": {
        "id": "nmg2ijt1NopE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "accuracy = f1_score(y_test, y_pred)\n",
        "print(f'F1: {accuracy:.2f}')\n",
        "\n",
        "accuracy = precision_score(y_test, y_pred)\n",
        "print(f'Precision: {accuracy:.2f}')\n",
        "\n",
        "accuracy = recall_score(y_test, y_pred)\n",
        "print(f'Recall: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B73PWoCyNznM",
        "outputId": "95acac02-4b18-4398-8941-22a5a35b0a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.78\n",
            "F1: 0.82\n",
            "Precision: 0.80\n",
            "Recall: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# save\n",
        "with open('model_tuning.pkl','wb') as f:\n",
        "    pickle.dump(clf_tuning,f)"
      ],
      "metadata": {
        "id": "uPr8vlFoPwja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = load_images(\"/content/asap1.png\", \"smoke\")\n",
        "label = label_encoder.transform(label)\n",
        "image = scaler.transform(image)\n",
        "pred = clf_tuning.predict(image)\n",
        "print(label_encoder.inverse_transform(pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpZJSeGVP5Kw",
        "outputId": "fac0076e-7b9f-48c3-d5bd-2f4a59cc83ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['smoke']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = load_images(\"/content/noasap1.png\", \"default\")\n",
        "label = label_encoder.transform(label)\n",
        "image = scaler.transform(image)\n",
        "pred = clf_tuning.predict(image)\n",
        "print(label_encoder.inverse_transform(pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_1diYHsP4Oh",
        "outputId": "7273dcb4-0394-4e0a-a3b6-e8cde6910931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['smoke']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = load_images(\"//content/noasap2.jpeg\", \"default\")\n",
        "label = label_encoder.transform(label)\n",
        "image = scaler.transform(image)\n",
        "pred = clf_tuning.predict(image)\n",
        "print(label_encoder.inverse_transform(pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2CwgYImP0ep",
        "outputId": "e5327b14-429d-4856-8e8e-7b6af7ebe374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['default']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "-HXsxMr0R1nf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "fCG9aL3mR4Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "import graphviz"
      ],
      "metadata": {
        "id": "ZoFHnjJiS4zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "clf = pickle.load(open(\"/content/model_tuning.pkl\", \"rb\"))"
      ],
      "metadata": {
        "id": "QjM-DPr1SKtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dot_data = tree.export_graphviz(clf, out_file=None,\n",
        "                                feature_names=[str(i) for i in range(X_train.shape[1])],\n",
        "                                filled=True, rounded=True,\n",
        "                                special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"decision_tree_image\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "z8ACdTVbS9nJ",
        "outputId": "9a70b6f3-432f-4ab4-a0d0-20f2166301b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'decision_tree_image.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}